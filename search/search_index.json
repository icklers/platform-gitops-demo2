{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the Crossplane GitOps Tutorial","text":"<p>This tutorial is designed for Senior DevOps Engineers who want to master the art of building and managing cloud infrastructure using a GitOps workflow, powered by Crossplane and ArgoCD.</p> <p>We will move beyond simple examples and dive deep into building a robust, production-ready Internal Developer Platform (IDP). You will learn how to manage infrastructure for multiple cloud providers, enforce security policies, and create a self-service ecosystem for your development teams.</p>"},{"location":"#what-you-will-learn","title":"What You Will Learn","text":"<ul> <li>Infrastructure as Code (IaC) with Crossplane: Define, compose, and manage your cloud resources (like Kubernetes clusters, databases, and networking) directly from Kubernetes YAML.</li> <li>GitOps with ArgoCD: Use Git as the single source of truth for both your infrastructure and application deployments.</li> <li>Multi-Cloud Provisioning: Learn to provision and manage resources across Azure, Hetzner, and Google Cloud Platform (GCP).</li> <li>Production-Ready Patterns: Implement best practices for security, observability, and repository management.</li> <li>Platform Engineering: Build a true self-service platform that empowers developers to provision the resources they need, when they need them.</li> </ul>"},{"location":"#prerequisites","title":"Prerequisites","text":"<p>This is an advanced course. We assume you have a strong, hands-on understanding of:</p> <ul> <li>Kubernetes: You should be comfortable with <code>kubectl</code>, Kubernetes objects (Deployments, Services, etc.), and general cluster administration.</li> <li>Docker: You should know how to build, run, and manage Docker containers.</li> <li>Git: You should be proficient with core Git commands, branching, and pull requests.</li> <li>General Cloud Concepts: You should understand basic concepts like VPCs, subnets, and IAM roles.</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<p>Ready to dive in? Let's begin by setting up your local development environment.</p> <p>\u27a1\ufe0f Start the Tutorial: Introduction</p>"},{"location":"troubleshooting/","title":"Troubleshooting","text":"<p>Even in a well-oiled GitOps machine, things can go wrong. This page provides a guide to debugging common issues in your Crossplane and ArgoCD setup.</p>"},{"location":"troubleshooting/#1-my-claim-isnt-becoming-ready","title":"1. My Claim Isn't Becoming <code>Ready</code>","text":"<p>This is the most common problem. Here's a systematic approach to debugging it.</p>"},{"location":"troubleshooting/#step-1-crossplane-trace","title":"Step 1: <code>crossplane trace</code>","text":"<p>This is always your first step. It will show you the entire resource tree and pinpoint which resource is failing.</p> <pre><code>crossplane trace &lt;KIND&gt; &lt;NAME&gt;\n# e.g., crossplane trace akscluster my-failing-cluster\n</code></pre> <p>Look for the resource that does not have <code>READY: True</code>.</p>"},{"location":"troubleshooting/#step-2-kubectl-describe-the-failing-resource","title":"Step 2: <code>kubectl describe</code> the Failing Resource","text":"<p>Once you've identified the failing resource, use <code>kubectl describe</code> to get more details.</p> <pre><code>kubectl describe &lt;KIND&gt; &lt;NAME&gt;\n# e.g., kubectl describe managedresource my-failing-vm\n</code></pre> <p>Look at the <code>Events</code> section at the bottom. This will often contain a specific error message from the Crossplane provider.</p> <p>Common Errors:</p> <ul> <li><code>403 Forbidden</code>: The Crossplane provider's Service Principal or credentials do not have the required IAM permissions in the cloud provider.</li> <li><code>InvalidRequest</code>: You have passed an invalid value in the claim, which was then passed to the cloud provider API. Check your claim's <code>spec</code>.</li> <li><code>NotFound</code>: The resource was deleted out-of-band (e.g., in the cloud console), and Crossplane is trying to update it.</li> </ul>"},{"location":"troubleshooting/#step-3-check-the-provider-pod-logs","title":"Step 3: Check the Provider Pod Logs","text":"<p>If the events aren't clear, look at the logs of the relevant Crossplane provider pod.</p> <pre><code># Find the provider pod\nkubectl get pods -n crossplane-system | grep provider-azure\n\n# Tail the logs\nkubectl logs -f -n crossplane-system &lt;PROVIDER_POD_NAME&gt;\n</code></pre> <p>The logs will give you the raw error messages from the cloud provider's API.</p>"},{"location":"troubleshooting/#2-argocd-app-is-degraded-or-progressing","title":"2. ArgoCD App is <code>Degraded</code> or <code>Progressing</code>","text":""},{"location":"troubleshooting/#degraded","title":"<code>Degraded</code>","text":"<ul> <li>Check the Health Check: The resource is failing its health check. Click on the resource in the ArgoCD UI to see the health status message.</li> <li>Crossplane Issue: Often, an ArgoCD app is <code>Degraded</code> because a Crossplane resource it manages is failing. Use the troubleshooting steps above to debug the Crossplane side.</li> </ul>"},{"location":"troubleshooting/#progressing","title":"<code>Progressing</code>","text":"<ul> <li>Missing Health Check: The most common reason for a resource to be stuck in <code>Progressing</code> is that ArgoCD doesn't have a custom health check for it. The resource might be perfectly healthy, but ArgoCD doesn't know how to verify it.</li> <li>Long-Running Operation: The resource is legitimately taking a long time to create (e.g., provisioning a large database).</li> </ul>"},{"location":"troubleshooting/#3-my-composition-isnt-being-selected","title":"3. My <code>Composition</code> Isn't Being Selected","text":"<p>If you create a claim and nothing happens (no <code>CompositeResource</code> is created), it means Crossplane could not find a <code>Composition</code> to satisfy the claim.</p> <ul> <li>Check Labels/Selectors: If your <code>Composition</code> uses a <code>claimSelector</code>, ensure the labels on your claim match the selector.</li> <li>Check <code>compositeTypeRef</code>: Ensure the <code>compositeTypeRef</code> in your <code>Composition</code> matches the <code>group</code>, <code>version</code>, and <code>kind</code> of the <code>CompositeResourceDefinition</code>.</li> <li>Check <code>claimNames</code>: Ensure the <code>claimNames</code> in your XRD match the <code>kind</code> of the claim you are creating.</li> </ul>"},{"location":"troubleshooting/#4-pods-are-in-imagepullbackoff","title":"4. Pods are in <code>ImagePullBackOff</code>","text":"<ul> <li>Check Image Name: You may have a typo in the container image name in your <code>Deployment</code> or <code>Composition</code>.</li> <li>Private Registry: If the image is in a private registry, you need to create an <code>imagePullSecret</code> and attach it to the <code>Pod</code>'s <code>ServiceAccount</code>.</li> <li>Kyverno Policy: If you are using an image signature policy, the pod may be blocked because the image is not signed or the signature is invalid. Check the Kyverno pod logs.</li> </ul> <p>By following these steps, you should be able to diagnose and resolve the vast majority of issues you encounter in your GitOps journey.</p>"},{"location":"advanced/","title":"Advanced Topics","text":""},{"location":"advanced/01-composition-functions/","title":"01: Extending Crossplane with Composition Functions","text":"<p>Patch-and-transform is a powerful way to create <code>Compositions</code>, but it has its limits. What if you need to add complex logic, conditional resource creation, or loop over a list to generate resources? For this, we use Composition Functions.</p>"},{"location":"advanced/01-composition-functions/#what-are-composition-functions","title":"What are Composition Functions?","text":"<p>A Composition Function is a custom program that you write, package as a container image, and reference in your <code>Composition</code>. When Crossplane reconciles your <code>CompositeResource</code>, it sends the <code>Observed</code> and <code>Desired</code> state to your function. Your function then returns a new <code>Desired</code> state, which Crossplane applies.</p> <p>This allows you to inject any logic you can imagine into the composition process.</p>"},{"location":"advanced/01-composition-functions/#why-use-them","title":"Why Use Them?","text":"<ul> <li>Conditional Logic: Only create a resource if a certain field in the claim is set (e.g., <code>if claim.spec.ha == true, create a read replica</code>).</li> <li>Looping: Create a variable number of resources based on a list in the claim (e.g., <code>for each port in claim.spec.firewallPorts, create a FirewallRule</code>).</li> <li>External Lookups: Call an external API to fetch data and use it to enrich your resources.</li> <li>Complex Validation: Implement validation logic that is too complex for OpenAPI schema validation.</li> </ul>"},{"location":"advanced/01-composition-functions/#how-they-work","title":"How They Work","text":"<p>Your <code>Composition</code> is modified to run in <code>Pipeline</code> mode, which consists of a series of steps. One of these steps can be your function.</p> <p>Example <code>Composition</code> with a Function:</p> <pre><code>apiVersion: apiextensions.crossplane.io/v1\nkind: Composition\nmetadata:\n  name: my-function-composition\nspec:\n  compositeTypeRef: # ...\n  mode: Pipeline\n  pipeline:\n    - step: patch-and-transform\n      functionRef:\n        name: function-patch-and-transform\n    - step: my-custom-logic\n      functionRef:\n        name: my-awesome-function\n      input:\n        apiVersion: my-fn.example.org/v1alpha1\n        kind: MyFunctionInput\n        spec:\n          someValue: \"hello world\"\n</code></pre> <p>In this example:</p> <ol> <li>The <code>mode</code> is set to <code>Pipeline</code>.</li> <li>The first step is the standard <code>patch-and-transform</code> function.</li> <li>The second step calls our custom function, <code>my-awesome-function</code>.</li> <li>We can pass custom <code>input</code> to our function.</li> </ol>"},{"location":"advanced/01-composition-functions/#writing-a-composition-function","title":"Writing a Composition Function","text":"<p>Composition Functions can be written in any language that can be packaged in a container. Go is a popular choice due to its strong typing and Kubernetes ecosystem tooling.</p> <p>Crossplane provides libraries (<code>crossplane-runtime/pkg/function</code> and <code>crossplane-runtime/pkg/function/proto</code>) to simplify the process.</p>"},{"location":"advanced/01-composition-functions/#the-functionrunner","title":"The <code>FunctionRunner</code>","text":"<p>Your function's <code>main.go</code> will typically use a <code>FunctionRunner</code>.</p> <pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n\n    \"github.com/crossplane/crossplane-runtime/pkg/errors\"\n    \"github.com/crossplane/crossplane-runtime/pkg/function\"\n    fnv1beta1 \"github.com/crossplane/function-sdk-go/proto/v1beta1\"\n)\n\nfunc main() {\n    function.Run(function.HandlerFunc(func(ctx context.Context, req *fnv1beta1.RunFunctionRequest) (*fnv1beta1.RunFunctionResponse, error) {\n        // 1. Get the observed and desired state from the request.\n        observed, err := function.ParseObservedResources(req)\n        if err != nil {\n            return nil, errors.Wrap(err, \"cannot parse observed resources\")\n        }\n        desired, err := function.ParseDesiredResources(req)\n        if err != nil {\n            return nil, errors.Wrap(err, \"cannot parse desired resources\")\n        }\n\n        // 2. Add your custom logic here.\n        // For example, loop over a field in the claim and add new resources to the `desired` map.\n\n        // 3. Return the modified desired state.\n        if err := function.ComposeDesiredResources(req, desired); err != nil {\n            return nil, errors.Wrap(err, \"cannot compose desired resources\")\n        }\n\n        return req, nil\n    }))\n}\n</code></pre>"},{"location":"advanced/01-composition-functions/#exercise-a-looping-function","title":"Exercise: A Looping Function","text":"<p>Objective: Create a Composition Function that creates a set of Azure Firewall rules based on a list in the claim.</p> <p>Tasks:</p> <ol> <li>Define the XRD: Create a <code>CompositeFirewall</code> with a claim, <code>Firewall</code>, that has a field <code>allowedPorts</code> which is an array of strings.</li> <li>Write the Function:<ul> <li>Create a new Go project for your function.</li> <li>The function should get the <code>allowedPorts</code> array from the claim.</li> <li>It should loop through the array.</li> <li>For each port, it should create a new Azure <code>FirewallRule</code> resource and add it to the desired state.</li> </ul> </li> <li>Package and Push: Build the function's Docker image and push it to a registry.</li> <li>Create the <code>Function</code> resource: Define a <code>Function</code> resource in your <code>platform</code> repository that points to your new image.</li> <li>Create the <code>Composition</code>: Create a <code>Composition</code> that uses your new function in its pipeline.</li> <li>Claim a <code>Firewall</code>: Create a <code>Firewall</code> claim with a list of ports.</li> <li>Verify: Check in the Azure portal that a firewall rule was created for each port in your claim.</li> </ol> <p>Composition Functions are an advanced topic, but they unlock the full potential of Crossplane, allowing you to build a truly powerful and customized Internal Developer Platform.</p> <p>\u27a1\ufe0f Next: Multi-Cluster Management</p>"},{"location":"advanced/02-multi-cluster-management/","title":"02: Multi-Cluster Management","text":"<p>We have successfully used Crossplane to provision Kubernetes clusters (AKS and GKE). This is known as Cluster as a Service. The next logical step is to manage the applications and configurations on those newly created clusters.</p> <p>This is the domain of Multi-Cluster Management (MCM).</p>"},{"location":"advanced/02-multi-cluster-management/#the-challenge","title":"The Challenge","text":"<p>How do we use our GitOps workflow, which is centered around our main KinD cluster, to push manifests and configurations to the new AKS and GKE clusters we are creating?</p>"},{"location":"advanced/02-multi-cluster-management/#solution-argocd-applicationsets-crossplane","title":"Solution: ArgoCD ApplicationSets + Crossplane","text":"<p>We can combine the power of Crossplane and ArgoCD ApplicationSets to create a fully automated, closed-loop multi-cluster management system.</p>"},{"location":"advanced/02-multi-cluster-management/#the-cluster-object","title":"The <code>Cluster</code> Object","text":"<p>ArgoCD has a concept of a <code>Cluster</code>. You can tell ArgoCD about a new remote cluster by creating a Kubernetes <code>Secret</code> with the cluster's kubeconfig.</p> <p>The <code>ApplicationSet</code> controller can then use this <code>Cluster</code> secret as a target for deploying applications.</p>"},{"location":"advanced/02-multi-cluster-management/#the-workflow","title":"The Workflow","text":"<ol> <li> <p>Crossplane Provisions a Cluster: We start by claiming an <code>AKSCluster</code> or <code>GKECluster</code> as we did in the previous sections.</p> </li> <li> <p>Crossplane Creates a Kubeconfig Secret: Our <code>Composition</code> is configured to patch the <code>kubeconfig</code> from the provisioned cluster into the connection details of the claim. This creates a <code>Secret</code> in our main KinD cluster.</p> </li> <li> <p>The <code>ApplicationSet</code> Generator: We will create an <code>ApplicationSet</code> that uses a <code>Cluster</code> generator. This generator automatically discovers any <code>Secret</code> that is labeled as an ArgoCD cluster secret.</p> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: ApplicationSet\nmetadata:\n  name: guestbook-to-all-clusters\nspec:\n  generators:\n  - clusters: {}\n  template:\n    metadata:\n      name: '{{name}}-guestbook'\n    spec:\n      project: default\n      source:\n        repoURL: https://github.com/argoproj/argocd-example-apps.git\n        targetRevision: HEAD\n        path: guestbook\n      destination:\n        server: '{{server}}'\n        namespace: guestbook\n</code></pre> </li> <li> <p>Labeling the Secret: We need to tell the <code>ApplicationSet</code> generator that our Crossplane-generated kubeconfig secret represents a new cluster. We can do this with a Composition Function or a simple Kubernetes controller that watches for our <code>AKSCluster</code> claims and automatically adds the <code>argocd.argoproj.io/secret-type: cluster</code> label to the generated secret.</p> </li> <li> <p>ArgoCD Deploys the App:</p> <ul> <li>The <code>ApplicationSet</code> controller discovers the newly labeled secret.</li> <li>It adds the new AKS/GKE cluster to ArgoCD's list of managed clusters.</li> <li>It then uses the <code>template</code> to generate a new ArgoCD <code>Application</code>.</li> <li>This new <code>Application</code> points to the <code>guestbook</code> app, but its <code>destination.server</code> is set to the API server of the new remote cluster.</li> <li>ArgoCD syncs the guestbook manifests to the new AKS/GKE cluster.</li> </ul> </li> </ol>"},{"location":"advanced/02-multi-cluster-management/#the-result-a-fully-automated-pipeline","title":"The Result: A Fully Automated Pipeline","text":"<p>With this pattern, the entire lifecycle is automated:</p> <ol> <li>A developer claims a new <code>AKSCluster</code> in a Git repository.</li> <li>Crossplane provisions the cluster.</li> <li>Crossplane creates a kubeconfig secret.</li> <li>A controller labels the secret for ArgoCD.</li> <li>The <code>ApplicationSet</code> detects the new cluster.</li> <li>ArgoCD deploys a standard set of baseline applications (e.g., an ingress controller, a monitoring agent, the guestbook app) to the new cluster without any human intervention.</li> </ol> <p>This is the pinnacle of GitOps-driven platform engineering. We have used Git to orchestrate the creation of a new cluster and the bootstrapping of all its day-1 applications.</p> <p>\u27a1\ufe0f Next: Troubleshooting</p>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/01-introduction/","title":"01: Introduction to the GitOps Workflow","text":"<p>Welcome to the first module of the Crossplane GitOps tutorial. In this section, we will lay the foundation for everything that follows. We'll start with a high-level overview of the core technologies and the architectural philosophy behind this course.</p>"},{"location":"getting-started/01-introduction/#the-core-components","title":"The Core Components","text":"<p>Our platform is built on three key pillars:</p> <ol> <li> <p>Crossplane: The infrastructure-as-code engine. Crossplane extends Kubernetes with Custom Resource Definitions (CRDs) that allow us to model infrastructure from any cloud provider as native Kubernetes objects. Instead of writing HCL, Bicep, or CloudFormation, we write YAML.</p> </li> <li> <p>ArgoCD: The GitOps engine. ArgoCD continuously monitors a Git repository and applies the desired state (defined in YAML) to our Kubernetes cluster. This ensures that our cluster's state always matches what's in Git.</p> </li> <li> <p>Nix &amp; Devbox: The environment management tools. Nix ensures that every developer on the team has the exact same version of every tool, library, and dependency. Devbox provides a user-friendly wrapper around Nix, making it easy to manage our development environment.</p> </li> </ol>"},{"location":"getting-started/01-introduction/#the-architectural-vision-a-true-idp","title":"The Architectural Vision: A True IDP","text":"<p>Our goal is not just to automate infrastructure provisioning. We are building an Internal Developer Platform (IDP). What does this mean?</p> <ul> <li>Self-Service for Developers: Developers can provision the infrastructure they need (e.g., a PostgreSQL database, a Redis cache, a Kubernetes cluster) by simply creating a YAML file and pushing it to Git. They don't need to be experts in Azure, GCP, or Hetzner.</li> <li>Platform Team as Enablers: The platform team (that's us!) defines the \"blueprints\" for this infrastructure using Crossplane Compositions. We control the security, networking, and configuration details, ensuring that all provisioned resources adhere to company standards.</li> <li>Git as the Single Source of Truth: Every single piece of infrastructure, from a single S3 bucket to an entire Kubernetes cluster, is defined declaratively in a Git repository. This provides a complete audit trail and enables powerful automation.</li> </ul>"},{"location":"getting-started/01-introduction/#what-we-will-build","title":"What We Will Build","text":"<p>By the end of this tutorial, you will have a fully functional, multi-cloud IDP running on a local KinD cluster. You will be able to:</p> <ul> <li>Define a new type of \"product\" (e.g., a <code>CompositePostgresInstance</code>) that bundles together all the necessary cloud resources.</li> <li>Provision that product on Azure, GCP, or Hetzner by creating a simple one-line YAML \"claim\".</li> <li>Automatically deploy applications to newly provisioned Kubernetes clusters.</li> <li>Monitor the health and status of your infrastructure using Prometheus and Grafana.</li> </ul> <p>This is a powerful paradigm shift for infrastructure management. Let's get started by setting up our development environment.</p> <p>\u27a1\ufe0f Next: Nix &amp; Devbox Setup</p>"},{"location":"getting-started/02-devbox-setup/","title":"02: Nix &amp; Devbox Setup","text":"<p>Reproducibility is critical for a stable GitOps workflow. We need to ensure that every engineer on the team, as well as our CI/CD pipelines, are using the exact same versions of our command-line tools. We will use Nix and Devbox to achieve this.</p>"},{"location":"getting-started/02-devbox-setup/#what-is-nix","title":"What is Nix?","text":"<p>Nix is a powerful package manager for Linux and macOS that makes package management reliable and reproducible. It allows you to create isolated, declarative, and version-pinned development environments.</p> <ul> <li>Declarative: You define the exact packages you need in a configuration file (<code>flake.nix</code>).</li> <li>Reproducible: Nix guarantees that anyone who uses this file will get the exact same version of every package, down to the last bit.</li> <li>Isolated: Projects can have their own set of dependencies without interfering with each other or your global system state.</li> </ul>"},{"location":"getting-started/02-devbox-setup/#what-is-devbox","title":"What is Devbox?","text":"<p>While Nix is incredibly powerful, its syntax can be steep. Devbox provides a user-friendly, JSON-based interface on top of Nix. It simplifies the process of managing your development environment.</p> <p>We have already defined the necessary tools in the <code>devbox.json</code> file at the root of this project. Take a moment to inspect it:</p> <pre><code>```json\n{\n  \"packages\": [\n    \"argocd@latest\",\n    \"mkdocs@latest\",\n    \"oh-my-zsh@latest\",\n    \"zsh@latest\",\n    \"kubectl@latest\",\n    \"gh@latest\",\n    \"uv@latest\"\n  ],\n  \"shell\": {\n    \"init_hook\": [\n      \"[ ! -d .venv ] &amp;&amp; uv venv\",\n      \"source .venv/bin/activate\",\n      \"export UV_LINK_MODE=copy\",\n      \"echo 'Welcome to the GitOps Tutorial Dev Environment!'\"\n    ],\n    \"scripts\": {\n      \"setup-tools\": [\n        \"uv pip sync\",\n        \"curl -sL \\\"https://raw.githubusercontent.com/crossplane/crossplane/main/install.sh\\\" | sh\"\n      ]\n    }\n  }\n}\n</code></pre> <p>Note on the <code>up</code> CLI: You may notice <code>up</code> in our packages list. This is the official command-line tool from Upbound, the creators of Crossplane. It provides helpful commands for managing Crossplane packages, configurations, and providers. While we will primarily use <code>kubectl</code> in this tutorial, <code>up</code> is an essential tool for advanced Crossplane development and is included here for completeness.</p> <p>Note on the Crossplane CLI and Python Dependencies: The Crossplane CLI (<code>crossplane</code>) and all Python dependencies for MkDocs are installed via the <code>devbox run setup-tools</code> command. This ensures you always have the latest compatible versions, which is crucial for compatibility with Crossplane's rapid development cycle and for building the documentation.</p> <p>As you can see, we have pinned the exact versions of <code>kubectl</code>, and all our other essential tools.</p>"},{"location":"getting-started/02-devbox-setup/#setup-instructions","title":"Setup Instructions","text":""},{"location":"getting-started/02-devbox-setup/#1-install-nix","title":"1. Install Nix","text":"<p>If you don't have Nix installed, follow the official installation guide. We recommend the multi-user installation.</p> <pre><code>sh &lt;(curl -L https://nixos.org/nix/install) --daemon\n</code></pre>"},{"location":"getting-started/02-devbox-setup/#2-install-devbox","title":"2. Install Devbox","text":"<p>Next, install Devbox.</p> <pre><code>curl -fsSL https://get.jetpack.io/devbox | bash\n</code></pre>"},{"location":"getting-started/02-devbox-setup/#3-activate-the-devbox-shell","title":"3. Activate the Devbox Shell","text":"<p>Now, navigate to the root of the <code>crossplane-gitops-tutorial</code> directory and run:</p> <pre><code>devbox shell\n</code></pre> <p>This command will:</p> <ol> <li>Read the <code>devbox.json</code> file.</li> <li>Use Nix to download and install the exact versions of all the packages listed.</li> <li>Activate a new shell session with all those tools available in your <code>PATH</code>.</li> </ol> <p>You are now in a fully reproducible development environment. Every command you run in this shell will use the tools defined in our project, not your globally installed versions.</p>"},{"location":"getting-started/02-devbox-setup/#4-install-project-tools","title":"4. Install Project Tools","text":"<p>Run the <code>setup-tools</code> script to install the Crossplane CLI and Python dependencies for MkDocs:</p> <pre><code>devbox run setup-tools\n</code></pre> <p>To verify, run:</p> <pre><code>kubectl version --client\n# Should output v1.29.2 or the version pinned in devbox.json\n\ncrossplane version --client\n# Should output v2.0.0 or the version pinned in devbox.json\n</code></pre> <p>With our environment set up, we can now install the core components.</p> <p>\u27a1\ufe0f Next: Local Cluster Setup</p>"},{"location":"getting-started/03-local-cluster-setup/","title":"03: Local Cluster Setup","text":"<p>With our Devbox environment activated, we have all the necessary command-line tools. Now, we need to create the local Kubernetes cluster that will serve as the foundation for our platform.</p>"},{"location":"getting-started/03-local-cluster-setup/#1-create-the-local-kubernetes-cluster","title":"1. Create the Local Kubernetes Cluster","text":"<p>We have provided a <code>kind-cluster.yaml</code> file inside the <code>gitops-bootstrap/kind-cluster/</code> directory. Take a moment to inspect its contents:</p> <pre><code>kind: Cluster\napiVersion: kind.x-k8s.io/v1alpha4\nnodes:\n- role: control-plane\n</code></pre> <p>Now, from within your <code>devbox shell</code>, run:</p> <pre><code>kind create cluster --config gitops-bootstrap/kind-cluster/kind-cluster.yaml\n</code></pre> <p>This will take a few minutes to provision a new, single-node Kubernetes cluster. Once it's complete, your <code>kubectl</code> context will automatically be configured to point to the new <code>kind-idp-tutorial</code> cluster.</p> <p>Verify the cluster is running:</p> <pre><code>kubectl cluster-info\n</code></pre> <p>With our cluster running, we are ready to bootstrap our GitOps engine, ArgoCD.</p> <p>\u27a1\ufe0f Next: GitOps Bootstrap</p>"},{"location":"getting-started/04-gitops-bootstrap/","title":"04: GitOps Bootstrap with ArgoCD","text":"<p>Now that we have a blank Kubernetes cluster, we will kick off our entire platform using a single command. This is the essence of a true GitOps workflow.</p>"},{"location":"getting-started/04-gitops-bootstrap/#the-gitops-bootstrap-process","title":"The GitOps Bootstrap Process","text":"<p>We will apply a single file to our cluster: <code>gitops-bootstrap/argocd/install.yaml</code>. This manifest contains the Custom Resource Definitions for ArgoCD.</p> <p>Immediately after, we will apply our <code>platform-core.yaml</code>. This special <code>ApplicationSet</code> resource instructs ArgoCD to manage its own configuration and all other platform components from our Git repository.</p>"},{"location":"getting-started/04-gitops-bootstrap/#1-create-your-platform-gitops-repository","title":"1. Create Your Platform GitOps Repository","text":"<p>This tutorial provides the content for your \"Platform GitOps Repo\". You will create a new GitHub repository and push this content to it.</p>"},{"location":"getting-started/04-gitops-bootstrap/#11-prepare-your-environment","title":"1.1 Prepare your environment","text":"<p>First, set your GitHub username as an environment variable. This is used to authenticate with the repository when ArgoCD pulls the manifests.</p> <pre><code>export GITHUB_USERNAME=\"\" # Replace with your GitHub username\n</code></pre> <p>Next set a name for your Platform GitOps repository. This is the repository you just created.</p> <pre><code>export GITHUB_REPO_NAME=\"\" # Replace with your Platform GitOps repository name\n</code></pre> <p>Next, set an environment variable with your Platform GitOps repository URL:</p> <pre><code>export PLATFORM_GITOPS_REPO_URL=\"https://github.com/$GITHUB_USERNAME/$GITHUB_REPO_NAME.git\" # Replace with your actual Platform GitOps repository URL\n</code></pre> <p>Validate the environment variables:</p> <pre><code>echo \"GITHUB_USERNAME: $GITHUB_USERNAME\"\necho \"GITHUB_REPO_NAME: $GITHUB_REPO_NAME\"\necho \"PLATFORM_GITOPS_REPO_URL: $PLATFORM_GITOPS_REPO_URL\"\n</code></pre> <p>If the output looks correct, you are ready to proceed.</p>"},{"location":"getting-started/04-gitops-bootstrap/#12-clone-this-tutorial-repository-to-your-local-machine","title":"1.2 Clone this tutorial repository to your local machine","text":"<pre><code>gh clone icklers/idp-tutorial\ncd idp-tutorial\n</code></pre>"},{"location":"getting-started/04-gitops-bootstrap/#13-create-the-github-repository","title":"1.3 Create the GitHub repository","text":"<p>Create your new Platform GitOps Repo on GitHub and push the content. This command will create a new private repository on GitHub push the current directory's content to it, and set it as the <code>origin</code> remote.</p> <pre><code>gh repo create $GITHUB_USERNAME/$GITHUB_REPO_NAME --public --source . --remote origin\n</code></pre> <p>This repository will now be your source of truth for all GitOps configurations.</p> <p>If you want to create a private repository, refer to the ArgoCD Documentation about Private Repositories in GitHub</p>"},{"location":"getting-started/04-gitops-bootstrap/#2-prepare-the-platform-coreyaml","title":"2. Prepare the <code>platform-core.yaml</code>","text":"<p>The <code>platform-core.yaml</code> manifest needs to point to your Platform GitOps repository. We will use a simple <code>sed</code> command to replace the placeholder with your repository URL.</p> <pre><code>sed -i \"s|__YOUR_PLATFORM_GITOPS_REPO_URL__|$PLATFORM_GITOPS_REPO_URL|g\" gitops-bootstrap/argocd/platform-core.yaml\n</code></pre> <p>Note on ApplicationSet Path: Ensure that the <code>path</code> in the <code>platform-core.yaml</code>'s Git generator is set to <code>platform-core</code> if your <code>crossplane.yaml</code> is directly within that directory in your Git repository. If you intend to have subdirectories within <code>platform-core</code> for different applications, then the path should be <code>platform-core/*</code>.</p>"},{"location":"getting-started/04-gitops-bootstrap/#3-apply-the-bootstrap-manifests","title":"3. Apply the Bootstrap Manifests","text":"<p>This is the only manual <code>kubectl apply</code> we will perform. First, we create the namespace for ArgoCD. Then, we apply the official installation manifest directly from the ArgoCD project's GitHub repository. This is the recommended way to ensure you are installing a stable and complete version of ArgoCD.</p> <p>Finally, we apply our <code>platform-core.yaml</code> to tell our new ArgoCD instance to start managing our platform from Git.</p> <pre><code># Create the namespace for ArgoCD\nkubectl create namespace argocd\n\n# Apply the official ArgoCD installation manifest\nkubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml\n\n# Apply the Platform Core ApplicationSet to start the GitOps sync\nkubectl apply -f gitops-bootstrap/argocd/platform-core.yaml\n</code></pre>"},{"location":"getting-started/04-gitops-bootstrap/#4-register-your-gitops-repository-with-argocd","title":"4. Register Your GitOps Repository with ArgoCD","text":"<p>ArgoCD needs to know about your GitOps repository to pull manifests from it. Before adding the repository, you need to log in to the ArgoCD server using the <code>argocd</code> CLI. You will use the admin password you retrieved earlier.</p> <p>First, retrieve the initial admin password for ArgoCD:</p> <pre><code>export ARGOCD_ADMIN_PASSWORD=$(kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath=\"{.data.password}\" | base64 -d)\n</code></pre> <p>Now, log in to the ArgoCD server using the <code>argocd</code> CLI.:</p> <pre><code>argocd login localhost:8080 --username admin --password $ARGOCD_ADMIN_PASSWORD\n</code></pre> <p>You will see a warning about insecure connections:\"</p> <pre><code>WARNING: server certificate had error: tls: failed to verify certificate: x509: certificate signed by unknown authority. Proceed insecurely (y/n)?\n</code></pre> <p>This is expected since we are using port-forwarding and did not set up TLS. You can safely ignore this warning for local development.</p> <p>Once logged in, you will need a GitHub Personal Access Token (PAT) with <code>repo</code> scope to allow ArgoCD to access your repository.</p> <p>Follow the prompts in your browser to complete the authentication. Once authenticated, you can close the browser tab. The <code>gh</code> CLI will store the PAT securely. Use the <code>argocd repo add</code> command to register your repository. We will use the <code>gh auth token</code> command to securely retrieve your PAT.</p> <pre><code>argocd repo add $PLATFORM_GITOPS_REPO_URL --username $GITHUB_USERNAME --password $(gh auth token)\n</code></pre> <p>If you encounter an authentication error, create a new GitHub Personal Access Token (classic) with <code>repo</code> scope in your GitHub settings. Set an expiration date for the token, copy it, and use it like this:</p> <pre><code>export GITHUB_PAT=\"your-personal-access-token\"\nargocd repo add $PLATFORM_GITOPS_REPO_URL --username $GITHUB_USERNAME --password $GITHUB_PAT\n</code></pre>"},{"location":"getting-started/04-gitops-bootstrap/#5-observe-the-magic","title":"5. Observe the Magic","text":"<p>ArgoCD is now installing and configuring itself, Crossplane, and all the providers and compositions defined in your Git repository. To watch this happen, access the ArgoCD UI.</p> <p>Then, port-forward the ArgoCD server:</p> <pre><code>kubectl port-forward svc/argocd-server -n argocd 8080:443\n</code></pre> <p>Echo the admin password for convenience, to use it when logging into the ArgoCD WebUI:</p> <pre><code>echo \"ArgoCD Admin Password: $ARGOCD_ADMIN_PASSWORD\"\n</code></pre> <p>Log in to <code>https://localhost:8080</code> with username <code>admin</code> and the retrieved password. You will see the <code>platform-core</code> and all the other applications syncing automatically.</p>"},{"location":"getting-started/04-gitops-bootstrap/#congratulations","title":"Congratulations!","text":"<p>You have successfully bootstrapped a fully functional GitOps workflow. From this point forward, we will interact with our system exclusively through Git.</p> <p>\u27a1\ufe0f Next Section: Repository Management</p>"},{"location":"gitops-fundamentals/","title":"GitOps Fundamentals","text":""},{"location":"gitops-fundamentals/01-argocd-setup/","title":"01: ArgoCD Setup for Crossplane","text":"<p>We have already installed ArgoCD, but to make it work effectively with Crossplane, we need to understand a few key configuration details.</p>"},{"location":"gitops-fundamentals/01-argocd-setup/#health-checks","title":"Health Checks","text":"<p>ArgoCD determines the health of a resource by running a series of Lua scripts. By default, it doesn't know how to interpret the status of Crossplane's custom resources. A <code>Composition</code> might be creating resources, but ArgoCD will show it as <code>Progressing</code> indefinitely.</p> <p>We need to provide custom health checks for Crossplane resources.</p> <p>Example Health Check for a Crossplane <code>Composition</code>:</p> <pre><code>-- health.lua\nhs = {}\nhs.status = \"Healthy\"\nhs.message = obj.status.conditions[1].message\nif obj.status.conditions[1].type ~= \"Ready\" or obj.status.conditions[1].status ~= \"True\" then\n  hs.status = \"Progressing\"\nend\nreturn hs\n</code></pre> <p>This script tells ArgoCD to look at the <code>status.conditions</code> array of a Composition resource. If the condition with <code>type: Ready</code> has a <code>status: \"True\"</code>, then the resource is considered <code>Healthy</code>.</p>"},{"location":"gitops-fundamentals/01-argocd-setup/#how-to-apply-health-checks","title":"How to Apply Health Checks","text":"<p>You can add these custom health checks to the <code>argocd-cm</code> ConfigMap in the <code>argocd</code> namespace.</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: argocd-cm\n  namespace: argocd\ndata:\n  resource.customizations: |\n    apiextensions.crossplane.io/Composition:\n      health.lua: |\n        -- ... (lua script from above) ...\n</code></pre> <p>We have already applied a set of standard Crossplane health checks as part of our bootstrap process.</p>"},{"location":"gitops-fundamentals/01-argocd-setup/#rbac-for-crossplane-resources","title":"RBAC for Crossplane Resources","text":"<p>By default, the ArgoCD Application Controller does not have permission to create or manage cluster-scoped resources like <code>Compositions</code> or <code>CompositeResourceDefinitions</code>. We need to grant it these permissions.</p> <p>This is done by creating a <code>ClusterRole</code> and a <code>ClusterRoleBinding</code>.</p> <p>Example <code>ClusterRole</code>:</p> <pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: argocd-crossplane-manager-role\nrules:\n- apiGroups:\n  - apiextensions.crossplane.io\n  resources:\n  - compositions\n  - compositeresourcedefinitions\n  verbs:\n  - \"*\"\n</code></pre> <p>Then, you bind this role to the ArgoCD Application Controller's Service Account.</p> <p>This is also handled automatically by our bootstrap configuration.</p>"},{"location":"gitops-fundamentals/01-argocd-setup/#sync-options","title":"Sync Options","text":"<p>When working with CRDs, it's often necessary to tell ArgoCD to manage them in a specific way. The most common issue is that a CRD is applied, and then a Custom Resource (CR) that uses that CRD is applied immediately after. This can lead to a race condition where the CR is created before the CRD is fully recognized by the Kubernetes API server.</p> <p>To solve this, we use a Sync Hook:</p> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: my-app\n  annotations:\n    argocd.argoproj.io/sync-wave: \"1\"\n# ...\n---\napiVersion: my.crd.io/v1alpha1\nkind: MyCustomResource\nmetadata:\n  name: my-cr\n  annotations:\n    argocd.argoproj.io/sync-wave: \"2\"\n# ...\n</code></pre> <p>By adding <code>sync-wave</code> annotations, we can instruct ArgoCD to apply resources in a specific order. Resources with a lower sync-wave number are applied first, and ArgoCD waits for them to become healthy before proceeding to the next wave.</p> <p>We use this pattern extensively in our bootstrap process to ensure that Crossplane Providers are healthy before we try to create any Compositions.</p> <p>\u27a1\ufe0f Next: Crossplane Integration</p>"},{"location":"gitops-fundamentals/02-crossplane-integration/","title":"02: Crossplane Integration with ArgoCD","text":"<p>Now that ArgoCD is configured to understand Crossplane, let's look at how they work together to create our GitOps-powered IDP.</p>"},{"location":"gitops-fundamentals/02-crossplane-integration/#the-core-concept-separation-of-duties","title":"The Core Concept: Separation of Duties","text":"<p>The power of this integration comes from a clear separation of duties:</p> <ul> <li>Crossplane is the engine. It knows how to create infrastructure. It contains the logic for talking to cloud provider APIs. It defines the <code>Compositions</code> (the blueprints).</li> <li>ArgoCD is the delivery mechanism. It knows what to create. It watches our Git repositories and applies the desired state (the <code>Claims</code>) to the cluster.</li> </ul> <p>This separation is crucial. The Platform Team owns the Crossplane side of the house, and the Development Teams own the ArgoCD side (by creating claims in their repositories).</p>"},{"location":"gitops-fundamentals/02-crossplane-integration/#the-reconciliation-loop","title":"The Reconciliation Loop","text":"<p>Let's trace the end-to-end reconciliation loop:</p> <ol> <li> <p>A developer pushes a Claim to an <code>infra-</code> repository.     <pre><code># infra-dev/my-app-db.yaml\napiVersion: database.example.org/v1alpha1\nkind: MySQLInstance\nmetadata:\n  name: my-app-db\nspec:\n  storageGB: 20\n</code></pre></p> </li> <li> <p>ArgoCD syncs the repository. It sees the new <code>MySQLInstance</code> claim and applies it to the Kubernetes cluster using <code>kubectl apply</code>.</p> </li> <li> <p>Crossplane's <code>Claim Controller</code> wakes up. It sees a new <code>MySQLInstance</code> claim that has no corresponding <code>CompositeResource</code> (CR).</p> </li> <li> <p>Crossplane selects a <code>Composition</code>. It looks at the <code>claim</code> and, based on labels or other selectors, chooses a <code>Composition</code> that can satisfy it. For example, it might select <code>azure-mysql-server.v1alpha1.database.example.org</code>.</p> </li> <li> <p>Crossplane creates a <code>CompositeResource</code> (CR). It uses the selected <code>Composition</code> as a template to create a new <code>CompositeMySQLInstance</code> resource.</p> </li> <li> <p>Crossplane's <code>CompositeResource Controller</code> wakes up. It sees the new <code>CompositeMySQLInstance</code> and, based on the <code>Composition</code>, starts creating the actual managed resources (e.g., an <code>azure.dbformysql.flexible.FlexibleServer</code> and a <code>FirewallRule</code>).</p> </li> <li> <p>Crossplane Provider Controllers take over. The <code>provider-azure</code> controller sees the new Azure-specific resources and makes the necessary API calls to Azure to provision the database.</p> </li> <li> <p>Status is reported back up the chain. As the resources are created in Azure, the status is updated on the <code>FlexibleServer</code> resource, which updates the <code>CompositeMySQLInstance</code>, which in turn updates the <code>MySQLInstance</code> claim. The developer can run <code>kubectl get mysqlinstance my-app-db -o yaml</code> and see the connection details and status.</p> </li> </ol>"},{"location":"gitops-fundamentals/02-crossplane-integration/#viewing-the-sync-in-argocd","title":"Viewing the Sync in ArgoCD","text":"<p>This entire workflow is visible in the ArgoCD UI. You can click on the <code>infra-dev</code> Application and see:</p> <ul> <li>The <code>MySQLInstance</code> claim that was synced from Git.</li> <li>The <code>CompositeMySQLInstance</code> that was created by Crossplane.</li> <li>The underlying <code>FlexibleServer</code> and <code>FirewallRule</code> resources.</li> </ul> <p>ArgoCD provides a complete, real-time dependency graph of your entire infrastructure, from the Git commit all the way down to the individual cloud resources.</p> <p>This tight integration provides unparalleled visibility and control over your infrastructure.</p> <p>\u27a1\ufe0f Next: Workflow Patterns</p>"},{"location":"gitops-fundamentals/03-workflow-patterns/","title":"03: GitOps Workflow Patterns","text":"<p>With our tooling in place, we can now implement powerful GitOps workflows. Let's explore a few common patterns for managing infrastructure and applications.</p>"},{"location":"gitops-fundamentals/03-workflow-patterns/#pattern-1-infrastructure-promotion-git-based","title":"Pattern 1: Infrastructure Promotion (Git-based)","text":"<p>How do you promote infrastructure changes from a <code>dev</code> environment to a <code>staging</code> and <code>prod</code> environment?</p> <p>We will use a Git-based promotion strategy. Each environment has its own infrastructure repository (<code>infra-dev</code>, <code>infra-staging</code>, <code>infra-prod</code>).</p> <ol> <li> <p>Initial Deployment to Dev: A new database claim is first committed to the <code>main</code> branch of the <code>infra-dev</code> repository. ArgoCD deploys it to the <code>dev</code> cluster.</p> </li> <li> <p>Promotion to Staging: Once the change is validated in <code>dev</code>, we promote it to <code>staging</code>. Instead of copying files, we will create a pull request from the <code>infra-dev</code> repository to the <code>infra-staging</code> repository.</p> <ul> <li>This PR contains the exact commit with the new database claim.</li> <li>The Platform Team can review the PR, ensuring that the correct changes are being promoted.</li> <li>Once the PR is merged, ArgoCD deploys the claim to the <code>staging</code> cluster.</li> </ul> </li> <li> <p>Promotion to Production: The same process is repeated for production. A PR is opened from <code>infra-staging</code> to <code>infra-prod</code>.</p> </li> </ol> <p>This Git-based workflow provides a full audit trail for every change in every environment. We can see exactly who promoted what, and when.</p>"},{"location":"gitops-fundamentals/03-workflow-patterns/#pattern-2-application-and-infrastructure-together","title":"Pattern 2: Application and Infrastructure Together","text":"<p>Sometimes, an application has a dedicated piece of infrastructure that isn't shared. In this case, it makes sense to manage the application and its infrastructure in the same repository.</p> <p>Consider a microservice that needs a dedicated Redis cache.</p> <p>Repository: <code>my-microservice</code></p> <pre><code>my-microservice/\n\u251c\u2500\u2500 app/\n\u2502   \u2514\u2500\u2500 main.go\n\u251c\u2500\u2500 kubernetes/\n\u2502   \u251c\u2500\u2500 deployment.yaml\n\u2502   \u2514\u2500\u2500 service.yaml\n\u2514\u2500\u2500 infrastructure/\n    \u2514\u2500\u2500 redis-claim.yaml\n</code></pre> <p>We can create an ArgoCD <code>ApplicationSet</code> to manage this.</p> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: ApplicationSet\nmetadata:\n  name: microservices\nspec:\n  generators:\n    - git:\n        repoURL: https://github.com/your-org/my-microservice.git\n        revision: HEAD\n        directories:\n          - path: \"*\"\n  template:\n    metadata:\n      name: '{{path.basename}}'\n    spec:\n      project: default\n      source:\n        repoURL: https://github.com/your-org/my-microservice.git\n        targetRevision: HEAD\n        path: '{{path}}'\n      destination:\n        server: https://kubernetes.default.svc\n        namespace: '{{path.basename}}'\n</code></pre> <p>This <code>ApplicationSet</code> will:</p> <ol> <li>Scan the <code>my-microservice</code> repository for directories.</li> <li>For each directory (<code>kubernetes</code>, <code>infrastructure</code>), it will create a new ArgoCD <code>Application</code>.</li> <li>The <code>kubernetes</code> app will deploy the manifests to the <code>kubernetes</code> namespace.</li> <li>The <code>infrastructure</code> app will deploy the Redis claim to the <code>infrastructure</code> namespace.</li> </ol> <p>This pattern keeps related resources together and allows developers to manage their app's entire lifecycle from a single repository.</p>"},{"location":"gitops-fundamentals/03-workflow-patterns/#pattern-3-ephemeral-environments-for-pull-requests","title":"Pattern 3: Ephemeral Environments for Pull Requests","text":"<p>For true end-to-end testing, we want to spin up an entire environment for each pull request.</p> <ol> <li>A developer opens a PR in an application repository.</li> <li>A GitHub Action is triggered.</li> <li>The action creates a new infrastructure claim for a temporary database and a new Kubernetes <code>Deployment</code> manifest, both with the PR number in their name (e.g., <code>my-app-pr-123</code>).</li> <li>These temporary manifests are pushed to a dedicated <code>infra-pr</code> repository.</li> <li>ArgoCD deploys the temporary infrastructure and application.</li> <li>The GitHub Action runs integration tests against the temporary environment.</li> <li>When the PR is merged or closed, another GitHub Action runs to delete the temporary manifests from the <code>infra-pr</code> repo, and ArgoCD automatically tears down the environment.</li> </ol> <p>This powerful pattern allows for complete, isolated testing of every change before it hits your main environments.</p> <p>\u27a1\ufe0f Next Section: Security</p>"},{"location":"observability/","title":"Observability","text":""},{"location":"observability/01-health-checks/","title":"01: Health Checks and Resource Status","text":"<p>In a declarative system, how do we know if the actual state of the world matches our desired state? This is the fundamental question of observability in a GitOps workflow.</p> <p>Both Crossplane and ArgoCD provide rich status information that we can use to monitor the health of our system.</p>"},{"location":"observability/01-health-checks/#argocd-health-checks","title":"ArgoCD Health Checks","text":"<p>As we discussed in the \"GitOps Fundamentals\" section, ArgoCD uses Lua scripts to determine the health of a resource. A resource can be in one of the following states:</p> <ul> <li>Healthy: The resource is in its desired state.</li> <li>Progressing: The resource is in the process of being created or updated.</li> <li>Degraded: The resource has failed to reach its desired state.</li> <li>Suspended: The resource is intentionally not being reconciled.</li> <li>Missing: The resource is defined in Git but is not present in the cluster.</li> <li>Unknown: The health of the resource could not be determined.</li> </ul> <p>We have already configured custom health checks for our Crossplane resources, so the ArgoCD UI gives us a real-time, at-a-glance view of the health of our entire infrastructure stack.</p>"},{"location":"observability/01-health-checks/#crossplane-resource-status","title":"Crossplane Resource Status","text":"<p>Crossplane itself provides detailed status conditions on all its resources (<code>Claims</code>, <code>CompositeResources</code>, and <code>ManagedResources</code>).</p> <p>You can inspect the status of any Crossplane resource using <code>kubectl</code>.</p> <p>Example: Checking the status of a <code>MySQLInstance</code> claim.</p> <pre><code>kubectl get mysqlinstance my-app-db -o yaml\n</code></pre> <pre><code>apiVersion: database.example.org/v1alpha1\nkind: MySQLInstance\nmetadata:\n  name: my-app-db\n# ...\nstatus:\n  conditions:\n    - type: Ready\n      status: \"True\"\n      lastTransitionTime: \"2023-10-27T18:30:00Z\"\n      reason: Available\n      message: \"The composite resource is available and ready\"\n    - type: Synced\n      status: \"True\"\n      lastTransitionTime: \"2023-10-27T18:28:00Z\"\n      reason: ReconcileSuccess\n      message: \"Successfully reconciled composite resource\"\n  connectionDetails:\n    lastPublishedTime: \"2023-10-27T18:30:01Z\"\n  # ... other fields\n</code></pre> <p>Key fields to watch:</p> <ul> <li><code>status.conditions</code>: This array tells you the current state of the resource. The <code>Ready</code> condition with <code>status: \"True\"</code> is the most important indicator of health.</li> <li><code>status.connectionDetails</code>: For claims, this section will be populated with the connection information for the provisioned resource (e.g., database endpoint, username, password secret reference).</li> </ul>"},{"location":"observability/01-health-checks/#the-crossplane-cli","title":"The <code>crossplane</code> CLI","text":"<p>The <code>crossplane</code> command-line tool provides some helpful commands for observing the status of your resources.</p> <p><code>crossplane trace</code></p> <p>The <code>trace</code> command gives you a complete dependency tree for a given claim, showing you the <code>CompositeResource</code> and all the underlying <code>ManagedResources</code>.</p> <pre><code>crossplane trace mysqlinstance my-app-db\n</code></pre> <p>Output:</p> <pre><code>NAME                                            READY   STATUS    AGE\nMySQLInstance/my-app-db                         True    Available 5m\n\u2514\u2500\u2500 CompositeMySQLInstance/my-app-db-xyz123     True    Available 5m\n    \u251c\u2500\u2500 FlexibleServer/my-app-db-server         True    Available 4m\n    \u2514\u2500\u2500 FirewallRule/my-app-db-fw               True    Available 3m\n</code></pre> <p>This is an invaluable tool for debugging. If a claim is not becoming <code>Ready</code>, you can use <code>trace</code> to pinpoint exactly which underlying resource is failing.</p> <p>By combining the ArgoCD UI with the detailed status information from Crossplane, we can build a comprehensive picture of our system's health.</p> <p>\u27a1\ufe0f Next: Monitoring with Prometheus</p>"},{"location":"observability/02-monitoring-with-prometheus/","title":"02: Monitoring with Prometheus","text":"<p>Health checks give us a binary status (is it working or not?), but for true observability, we need metrics. We need to track trends, understand performance, and be alerted to potential problems before they cause an outage.</p> <p>We will use Prometheus, the de facto standard for metrics and monitoring in the Kubernetes ecosystem.</p>"},{"location":"observability/02-monitoring-with-prometheus/#exposing-metrics-from-crossplane","title":"Exposing Metrics from Crossplane","text":"<p>Crossplane and its providers expose a wealth of metrics in the Prometheus format. These metrics give us deep insights into the reconciliation process.</p> <p>Key metrics include:</p> <ul> <li><code>crossplane_managed_resource_reconcile_total</code>: A counter of how many times a managed resource has been reconciled.</li> <li><code>crossplane_managed_resource_reconcile_errors_total</code>: A counter of how many reconciliation errors have occurred.</li> <li><code>crossplane_managed_resource_reconcile_duration_seconds</code>: A histogram of how long reconciliations are taking.</li> </ul> <p>These metrics are available on the <code>/metrics</code> endpoint of the Crossplane and Provider pods.</p>"},{"location":"observability/02-monitoring-with-prometheus/#setting-up-the-prometheus-stack","title":"Setting up the Prometheus Stack","text":"<p>We will use the <code>kube-prometheus-stack</code> Helm chart, which provides a complete, pre-configured monitoring solution:</p> <ul> <li>Prometheus: Scrapes and stores the metrics.</li> <li>Grafana: For visualizing the metrics in dashboards.</li> <li>Alertmanager: For sending alerts based on metric thresholds.</li> </ul>"},{"location":"observability/02-monitoring-with-prometheus/#installation","title":"Installation","text":"<pre><code># Add the Prometheus community repo\nhelm repo add prometheus-community https://prometheus-community.github.io/helm-charts\n\n# Install the stack\nhelm install prometheus prometheus-community/kube-prometheus-stack --namespace monitoring --create-namespace\n</code></pre>"},{"location":"observability/02-monitoring-with-prometheus/#servicemonitors","title":"ServiceMonitors","text":"<p>How does Prometheus know which pods to scrape? We use a CRD called <code>ServiceMonitor</code>.</p> <p>We need to create <code>ServiceMonitor</code> resources that tell Prometheus to scrape the metrics endpoints of the Crossplane and ArgoCD pods.</p> <p>Example <code>ServiceMonitor</code> for Crossplane:</p> <pre><code>apiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  name: crossplane-metrics\n  namespace: crossplane-system\nspec:\n  selector:\n    matchLabels:\n      app: crossplane\n  endpoints:\n  - port: http-metrics\n    path: /metrics\n</code></pre> <p>This resource tells the Prometheus Operator to find any <code>Service</code> in the <code>crossplane-system</code> namespace with the label <code>app: crossplane</code> and scrape its <code>http-metrics</code> port.</p> <p>We will add these <code>ServiceMonitor</code> manifests to our <code>platform</code> repository, so our monitoring configuration is also managed via GitOps.</p>"},{"location":"observability/02-monitoring-with-prometheus/#building-a-grafana-dashboard","title":"Building a Grafana Dashboard","text":"<p>With the metrics flowing into Prometheus, we can now build a Grafana dashboard to visualize the health of our Crossplane control plane.</p> <p>Key Panels to Include:</p> <ul> <li>Reconciliation Rate: A graph of the <code>rate(crossplane_managed_resource_reconcile_total[5m])</code>. This shows you how much work Crossplane is doing.</li> <li>Reconciliation Error Rate: A graph of the <code>rate(crossplane_managed_resource_reconcile_errors_total[5m])</code>. This should be zero. If it's not, something is wrong.</li> <li>Reconciliation Latency (95th percentile): A graph of <code>histogram_quantile(0.95, sum(rate(crossplane_managed_resource_reconcile_duration_seconds_bucket[5m])) by (le))</code>. This shows you the latency of your reconciliations.</li> <li>Total Managed Resources: A stat panel showing the output of <code>count(crossplane_managed_resources)</code>. This gives you an at-a-glance view of the size of your infrastructure.</li> </ul> <p>By building these dashboards, you create a single pane of glass for observing the health and performance of your entire infrastructure provisioning system.</p> <p>\u27a1\ufe0f Next: Alerting</p>"},{"location":"observability/03-alerting/","title":"03: Alerting on Infrastructure State","text":"<p>Dashboards are great for passive observation, but we need to be proactively notified when things go wrong. This is the job of Prometheus Alertmanager.</p> <p>Alertmanager allows us to define alerting rules based on Prometheus queries. When an alert fires, it can send notifications to a variety of receivers, such as Slack, PagerDuty, or email.</p>"},{"location":"observability/03-alerting/#defining-alerting-rules","title":"Defining Alerting Rules","text":"<p>Alerting rules are defined in a <code>PrometheusRule</code> CRD.</p> <p>Example <code>PrometheusRule</code> to detect failing reconciliations:</p> <pre><code>apiVersion: monitoring.coreos.com/v1\nkind: PrometheusRule\nmetadata:\n  name: crossplane-alerts\n  namespace: crossplane-system\nspec:\n  groups:\n  - name: crossplane.rules\n    rules:\n    - alert: CrossplaneReconciliationErrors\n      expr: rate(crossplane_managed_resource_reconcile_errors_total[5m]) &gt; 0\n      for: 5m\n      labels:\n        severity: critical\n      annotations:\n        summary: \"Crossplane is experiencing reconciliation errors\"\n        description: \"The rate of reconciliation errors for managed resources is greater than 0. This indicates a problem with one or more providers or managed resources.\"\n</code></pre> <p>This rule will:</p> <ol> <li><code>expr</code>: Continuously evaluate the rate of reconciliation errors over a 5-minute window.</li> <li><code>for</code>: If the expression is true for 5 consecutive minutes, the alert will enter the <code>Firing</code> state.</li> <li><code>labels</code>: Attach a <code>severity</code> label, which can be used for routing the alert (e.g., <code>critical</code> alerts go to PagerDuty, <code>warning</code> alerts go to Slack).</li> <li><code>annotations</code>: Provide a human-readable summary and description of the alert.</li> </ol>"},{"location":"observability/03-alerting/#important-alerts-to-configure","title":"Important Alerts to Configure","text":"<p>Here are some essential alerts you should configure for your Crossplane environment:</p> <ul> <li><code>CrossplaneReconciliationErrors</code> (Critical): As defined above. This is your most important alert.</li> <li><code>CrossplaneProviderNotReady</code> (Warning): Alert if a Crossplane <code>Provider</code> resource is not in the <code>Ready</code> state for more than 10 minutes.<ul> <li><code>expr: crossplane_provider_ready == 0</code></li> </ul> </li> <li><code>ArgoCDAppNotHealthy</code> (Warning): Alert if an ArgoCD Application has been in a <code>Degraded</code> state for more than 15 minutes.<ul> <li><code>expr: argocd_app_info{health_status!=\"Healthy\"} == 1</code></li> </ul> </li> <li><code>ClaimNotReady</code> (Warning): Alert if a Crossplane <code>Claim</code> has not reached the <code>Ready</code> state within 30 minutes of its creation. This requires tracking the creation timestamp.</li> </ul>"},{"location":"observability/03-alerting/#configuring-receivers","title":"Configuring Receivers","text":"<p>Once your rules are in place, you need to configure Alertmanager to send the notifications.</p> <p>This is done in the <code>prometheus-operator-alertmanager</code> secret.</p> <p>Example: Configuring a Slack receiver.</p> <pre><code># alertmanager.yaml\nglobal:\n  resolve_timeout: 5m\nroute:\n  group_by: ['job']\n  group_wait: 30s\n  group_interval: 5m\n  repeat_interval: 12h\n  receiver: 'null'\n  routes:\n  - receiver: 'slack-notifications'\n    match:\n      severity: critical\nreceivers:\n- name: 'null'\n- name: 'slack-notifications'\n  slack_configs:\n  - api_url: &lt;YOUR_SLACK_WEBHOOK_URL&gt;\n    channel: '#alerts-critical'\n</code></pre> <p>This configuration tells Alertmanager to send any alert with <code>severity: critical</code> to the <code>#alerts-critical</code> Slack channel.</p> <p>Like all our other configuration, these <code>PrometheusRule</code> and Alertmanager config files should be stored in your <code>platform</code> repository and managed via GitOps. This ensures that your alerting and monitoring strategy evolves along with your infrastructure.</p> <p>\u27a1\ufe0f Next Section: Advanced Topics</p>"},{"location":"providers/azure/","title":"Azure Provider","text":""},{"location":"providers/azure/01-setup/","title":"01: Setting up the Azure Provider","text":"<p>Now we will configure Crossplane to connect to a specific cloud provider: Microsoft Azure.</p> <p>The Crossplane <code>provider-azure</code> package contains all the necessary controllers and <code>ManagedResource</code> definitions to interact with the Azure Resource Manager (ARM) API.</p>"},{"location":"providers/azure/01-setup/#1-installing-the-provider","title":"1. Installing the Provider","text":"<p>First, we need to install the Azure Provider into our Crossplane installation. This is done by creating a <code>Provider</code> resource.</p> <p>File: <code>gitops-bootstrap/platform/provider-azure.yaml</code></p> <pre><code>apiVersion: pkg.crossplane.io/v1\nkind: Provider\nmetadata:\n  name: provider-azure\nspec:\n  package: \"xpkg.upbound.io/upbound/provider-azure:v1.2.0\"\n</code></pre> <p>This manifest tells Crossplane to download and install the specified version of the Azure provider package. We have already included this in our bootstrap process, so the provider is already installed in your cluster.</p> <p>You can verify this by running:</p> <pre><code>kubectl get providers\n</code></pre>"},{"location":"providers/azure/01-setup/#2-configuring-authentication","title":"2. Configuring Authentication","text":"<p>Next, Crossplane needs credentials to authenticate with your Azure subscription. We will use a Workload Identity for this, which is the most secure method for applications running in Kubernetes to access Azure resources.</p>"},{"location":"providers/azure/01-setup/#high-level-steps","title":"High-Level Steps","text":"<ol> <li>Create an Azure AD Application and Service Principal: This will be the identity that Crossplane uses.</li> <li>Create a Federated Identity Credential: This links the Azure AD Service Principal to a Kubernetes Service Account.</li> <li>Grant Permissions: Assign the necessary RBAC roles (e.g., <code>Contributor</code>) to the Service Principal on your Azure subscription.</li> <li>Create a <code>ProviderConfig</code>: This Kubernetes resource tells the Crossplane Azure Provider how to authenticate.</li> </ol>"},{"location":"providers/azure/01-setup/#creating-the-providerconfig","title":"Creating the <code>ProviderConfig</code>","text":"<p>Once you have set up the necessary resources in Azure, you will create a <code>ProviderConfig</code> manifest. Remember to replace the placeholder values for <code>clientId</code>, <code>tenantId</code>, and <code>subscriptionID</code> with your actual Azure credentials.</p> <p>File: <code>platform/provider-configs/azure.yaml</code></p> <pre><code>apiVersion: azure.upbound.io/v1beta1\nkind: ProviderConfig\nmetadata:\n  name: azure-default\nspec:\n  credentials:\n    source: \"WorkloadIdentity\"\n    workloadIdentity:\n      clientId: \"&lt;AZURE_CLIENT_ID&gt;\" # The client ID of your AAD Application\n      tenantId: \"&lt;AZURE_TENANT_ID&gt;\" # The tenant ID of your Azure subscription\n  subscriptionID: \"&lt;AZURE_SUBSCRIPTION_ID&gt;\"\n</code></pre> <p>This manifest instructs the Azure provider to use the Workload Identity associated with the specified <code>clientId</code> and <code>tenantId</code>.</p> <p>Important: The <code>ProviderConfig</code> is a cluster-scoped resource. The <code>name: default</code> is a convention. You can have multiple <code>ProviderConfig</code> resources if you need to connect to different Azure subscriptions or tenants.</p>"},{"location":"providers/azure/01-setup/#applying-the-providerconfig","title":"Applying the <code>ProviderConfig</code>","text":"<p>This <code>ProviderConfig</code> manifest should be stored in your <code>platform</code> repository and synced by ArgoCD. Once it is applied, the Azure provider will attempt to authenticate with Azure.</p> <p>You can check the status of the provider:</p> <pre><code>kubectl get providerconfig\n</code></pre> <p>Look for the <code>Ready</code> status to be <code>True</code>.</p>"},{"location":"providers/azure/01-setup/#conclusion","title":"Conclusion","text":"<p>With the <code>Provider</code> installed and the <code>ProviderConfig</code> applied, Crossplane is now ready to start provisioning resources in your Azure subscription.</p> <p>In the next section, we will create a <code>Composition</code> to define a production-ready Azure Kubernetes Service (AKS) cluster.</p> <p>\u27a1\ufe0f Next: Provisioning AKS</p>"},{"location":"providers/azure/02-provisioning-aks/","title":"02: Provisioning AKS Clusters","text":"<p>With the Azure provider configured, we can now define our first infrastructure \"product\": a production-ready Azure Kubernetes Service (AKS) cluster.</p> <p>We will create a <code>Composition</code> that bundles together all the necessary Azure resources to create a secure, reliable AKS cluster.</p>"},{"location":"providers/azure/02-provisioning-aks/#defining-the-compositeakscluster-xrd","title":"Defining the <code>CompositeAKSCluster</code> XRD","text":"<p>First, we define the API for our new resource. This is the <code>CompositeResourceDefinition</code> (XRD).</p> <p>File: <code>compositions/azure/aks.yaml</code></p> <pre><code>apiVersion: apiextensions.crossplane.io/v1\nkind: CompositeResourceDefinition\nmetadata:\n  name: compositeaksclusters.cluster.example.org\nspec:\n  group: cluster.example.org\n  names:\n    kind: CompositeAKSCluster\n    plural: compositeaksclusters\n  claimNames:\n    kind: AKSCluster\n    plural: aksclusters\n  versions:\n  - name: v1alpha1\n    served: true\n    referenceable: true\n    schema:\n      openAPIV3Schema:\n        type: object\n        properties:\n          spec:\n            type: object\n            properties:\n              region:\n                type: string\n                description: \"The Azure region to deploy the cluster in.\"\n              nodeSize:\n                type: string\n                description: \"The VM size for the worker nodes.\"\n                default: \"Standard_D2s_v3\"\n              nodeCount:\n                type: integer\n                description: \"The number of worker nodes.\"\n                default: 3\n            required:\n              - region\n</code></pre> <p>This XRD defines a new Kubernetes resource called <code>AKSCluster</code> with a <code>spec</code> that allows developers to specify the <code>region</code>, <code>nodeSize</code>, and <code>nodeCount</code>.</p>"},{"location":"providers/azure/02-provisioning-aks/#composing-the-aks-cluster","title":"Composing the AKS Cluster","text":"<p>Next, we define the <code>Composition</code>. This is where we specify which Azure resources will be created to satisfy an <code>AKSCluster</code> claim.</p> <p>File: <code>compositions/azure/aks.yaml</code> (continued)</p> <pre><code>---\napiVersion: apiextensions.crossplane.io/v1\nkind: Composition\nmetadata:\n  name: aks-cluster.v1alpha1.cluster.example.org\n  labels:\n    provider: azure\nspec:\n  compositeTypeRef:\n    apiVersion: cluster.example.org/v1alpha1\n    kind: CompositeAKSCluster\n  resources:\n    - name: resourceGroup\n      base:\n        apiVersion: azure.upbound.io/v1beta1\n        kind: ResourceGroup\n        spec:\n          forProvider:\n            location: \"from-field-path(spec.region)\"\n    - name: virtualNetwork\n      base:\n        apiVersion: network.azure.upbound.io/v1beta1\n        kind: VirtualNetwork\n        spec:\n          forProvider:\n            resourceGroupNameSelector:\n              matchControllerRef: true\n            location: \"from-field-path(spec.region)\"\n            addressSpace: [\"10.0.0.0/16\"]\n    - name: subnet\n      base:\n        apiVersion: network.azure.upbound.io/v1beta1\n        kind: Subnet\n        spec:\n          forProvider:\n            resourceGroupNameSelector:\n              matchControllerRef: true\n            virtualNetworkNameSelector:\n              matchControllerRef: true\n            addressPrefixes: [\"10.0.1.0/24\"]\n    - name: aksCluster\n      base:\n        apiVersion: containerservice.azure.upbound.io/v1beta1\n        kind: KubernetesCluster\n        spec:\n          forProvider:\n            resourceGroupNameSelector:\n              matchControllerRef: true\n            location: \"from-field-path(spec.region)\"\n            dnsPrefix: \"from-field-path(metadata.name)\"\n            defaultNodePool:\n              - name: default\n                vmSize: \"from-field-path(spec.nodeSize)\"\n                nodeCount: \"from-field-path(spec.nodeCount)\"\n                vnetSubnetIdSelector:\n                  matchControllerRef: true\n            identity:\n              type: \"SystemAssigned\"\n      patches:\n        # Patch the connection secret to the claim\n        - fromFieldPath: \"status.atProvider.kubeConfigRaw\"\n          toFieldPath: \"status.connectionDetails.kubeconfig\"\n</code></pre>"},{"location":"providers/azure/02-provisioning-aks/#key-concepts-in-this-composition","title":"Key Concepts in this Composition","text":"<ul> <li><code>resources</code> array: We are composing four Azure resources: a <code>ResourceGroup</code>, a <code>VirtualNetwork</code>, a <code>Subnet</code>, and a <code>KubernetesCluster</code>.</li> <li><code>from-field-path</code> patches: We are patching values from the <code>AKSCluster</code> claim (e.g., <code>spec.region</code>) into the <code>spec</code> of the managed resources.</li> <li><code>matchControllerRef</code> selectors: Instead of hardcoding names, we use selectors to link resources together. For example, the <code>VirtualNetwork</code> will automatically be created in the <code>ResourceGroup</code> that was created as part of this same <code>Composition</code>.</li> <li>Connection Secret Patching: We are patching the <code>kubeConfigRaw</code> from the <code>KubernetesCluster</code> resource into the connection details of the <code>AKSCluster</code> claim. This allows developers to get the kubeconfig for their new cluster directly from the claim.</li> </ul>"},{"location":"providers/azure/02-provisioning-aks/#exercise-claiming-an-aks-cluster","title":"Exercise: Claiming an AKS Cluster","text":"<p>Objective: Provision your first AKS cluster using the new <code>Composition</code>.</p> <p>Tasks:</p> <ol> <li>Create a Claim: In your <code>infra-dev</code> repository, create a new file named <code>my-aks-cluster.yaml</code>.</li> <li>Define the Claim: In the file, define an <code>AKSCluster</code> claim. Choose a name and an Azure region.     <pre><code>apiVersion: cluster.example.org/v1alpha1\nkind: AKSCluster\nmetadata:\n  name: my-first-aks-cluster\nspec:\n  region: \"westeurope\"\n  nodeCount: 2\n</code></pre></li> <li>Commit and Push: Commit the new file to the <code>main</code> branch of your <code>infra-dev</code> repository.</li> <li>Observe in ArgoCD: Watch in the ArgoCD UI as the new <code>AKSCluster</code> claim is synced.</li> <li>Observe in Crossplane: Use <code>crossplane trace akscluster my-first-aks-cluster</code> to see the underlying Azure resources being provisioned.</li> <li>Get the Kubeconfig: Once the cluster is ready, get the kubeconfig from the claim's secret and connect to your new AKS cluster.</li> </ol> <p>Success Criteria:</p> <ul> <li>A new AKS cluster is successfully provisioned in your Azure subscription.</li> <li>You can connect to the new cluster using the kubeconfig from the claim's secret.</li> </ul> <p>\u27a1\ufe0f Next Section: Hetzner Provider</p>"},{"location":"providers/google/","title":"GCP","text":""},{"location":"providers/google/01-setup/","title":"01: Setting up the GCP (GKE) Provider","text":"<p>To complete our multi-cloud showcase, we will now add Google Cloud Platform (GCP) to our control plane, focusing on provisioning Google Kubernetes Engine (GKE) clusters.</p>"},{"location":"providers/google/01-setup/#1-installing-the-provider","title":"1. Installing the Provider","text":"<p>As with our other providers, we first ensure the GCP provider package is installed.</p> <p>File: <code>gitops-bootstrap/platform/provider-gcp.yaml</code></p> <pre><code>apiVersion: pkg.crossplane.io/v1\nkind: Provider\nmetadata:\n  name: provider-gcp\nspec:\n  package: \"xpkg.upbound.io/upbound/provider-gcp:v1.3.0\"\n</code></pre> <p>This is part of our standard bootstrap process.</p>"},{"location":"providers/google/01-setup/#2-configuring-authentication","title":"2. Configuring Authentication","text":"<p>GCP authentication is similar to Azure's. We will use Workload Identity to securely connect Crossplane to GCP.</p>"},{"location":"providers/google/01-setup/#high-level-steps","title":"High-Level Steps","text":"<ol> <li>Create a GCP Service Account: This is the identity Crossplane will use.</li> <li>Grant IAM Roles: Assign the necessary roles to the Service Account (e.g., <code>roles/container.admin</code> for managing GKE).</li> <li>Create a Workload Identity Pool and Provider: This allows Kubernetes Service Accounts to impersonate GCP Service Accounts.</li> <li>Bind the KSA to the GSA: Create an IAM policy binding that links the Crossplane provider's Kubernetes Service Account to the GCP Service Account.</li> </ol>"},{"location":"providers/google/01-setup/#3-create-the-providerconfig","title":"3. Create the <code>ProviderConfig</code>","text":"<p>Once the GCP resources are configured, we create the <code>ProviderConfig</code>.</p> <p>File: <code>platform/provider-configs/gcp.yaml</code></p> <pre><code>apiVersion: gcp.upbound.io/v1beta1\nkind: ProviderConfig\nmetadata:\n  name: gcp-default\nspec:\n  projectID: \"&lt;YOUR_GCP_PROJECT_ID&gt;\"\n  credentials:\n    source: \"WorkloadIdentity\"\n    workloadIdentity:\n      serviceAccountEmail: \"&lt;GCP_SERVICE_ACCOUNT_EMAIL&gt;\"\n</code></pre> <p>This <code>ProviderConfig</code> tells the GCP provider:</p> <ul> <li>Which GCP <code>projectID</code> to operate in.</li> <li>To use <code>WorkloadIdentity</code> for authentication.</li> <li>The specific GCP Service Account to impersonate.</li> </ul> <p>After syncing this manifest from your <code>platform</code> repository, the GCP provider will be ready.</p> <p>Check its status:</p> <pre><code>kubectl get providerconfig gcp-default -o yaml\n</code></pre>"},{"location":"providers/google/01-setup/#exercise-create-a-gke-composition","title":"Exercise: Create a GKE Composition","text":"<p>Objective: Create a <code>Composition</code> for provisioning a GKE cluster.</p> <p>Tasks:</p> <ol> <li>Define the XRD: Create a <code>CompositeResourceDefinition</code> for a <code>CompositeGKECluster</code>. The claim, <code>GKECluster</code>, should have fields for <code>region</code>, <code>machineType</code>, and <code>nodeCount</code>.</li> <li>Define the Composition: The <code>Composition</code> should create a <code>gcp.container.Cluster</code> resource.<ul> <li>Map the fields from the claim to the <code>Cluster</code> resource's spec.</li> <li>Patch the connection details (kubeconfig, endpoint, certificate) from the <code>Cluster</code> back to the <code>GKECluster</code> claim.</li> </ul> </li> <li>Commit and Push: Add the new <code>Composition</code> to your <code>platform</code> repository.</li> <li>Claim a GKE Cluster: In your <code>infra-dev</code> repository, create a <code>GKECluster</code> claim.</li> <li>Verify: Use <code>crossplane trace</code> and the GCP Console to verify that the GKE cluster is being provisioned.</li> </ol> <p>By completing this exercise, you will have a single, unified control plane capable of provisioning and managing Kubernetes clusters across Azure (AKS), GCP (GKE), and even on bare metal with a provider like Hetzner. This is the core value proposition of building an Internal Developer Platform with Crossplane.</p> <p>\u27a1\ufe0f Next Section: Advanced Topics</p>"},{"location":"repository-management/","title":"Repository Management","text":""},{"location":"repository-management/01-multi-repo-strategy/","title":"01: Multi-Repo Strategy for GitOps","text":"<p>As a GitOps environment grows, managing all your code in a single repository (a \"mono-repo\") can become cumbersome. We advocate for a multi-repo strategy, which provides better separation of concerns, more granular access control, and clearer ownership.</p>"},{"location":"repository-management/01-multi-repo-strategy/#our-recommended-repository-structure","title":"Our Recommended Repository Structure","text":"<p>We propose a three-tiered repository structure:</p> <ol> <li> <p>Platform Repository (This one): This repository contains the core platform configuration. It defines the \"shape\" of your IDP.</p> <ul> <li>ArgoCD bootstrap configuration (<code>app-of-apps</code>).</li> <li>Crossplane Provider configurations.</li> <li>Crossplane Compositions (the blueprints for your infrastructure).</li> <li>RBAC policies and security configurations.</li> <li>Audience: Platform Engineering team.</li> </ul> </li> <li> <p>Infrastructure-as-Code (IaC) Repositories: Each of these repositories defines a specific piece of infrastructure using the Compositions from the platform repo.</p> <ul> <li>Contains Crossplane Claims (e.g., <code>CompositePostgresInstance</code>, <code>CompositeAKSCluster</code>).</li> <li>One repository per environment (e.g., <code>infra-dev</code>, <code>infra-staging</code>, <code>infra-prod</code>).</li> <li>Audience: DevOps / SRE / Platform team.</li> </ul> </li> <li> <p>Application Repositories: These are the standard repositories containing your microservice code.</p> <ul> <li>Contains application source code (Go, Python, Java, etc.).</li> <li>Contains Kubernetes manifests for deploying the application (Deployments, Services, Ingress, etc.).</li> <li>May contain a Crossplane Claim if the application requires its own dedicated infrastructure (e.g., a specific database).</li> <li>Audience: Development teams.</li> </ul> </li> </ol>"},{"location":"repository-management/01-multi-repo-strategy/#why-multi-repo","title":"Why Multi-Repo?","text":"Benefit Description Clear Ownership It's immediately clear which team owns which part of the system. Developers own their apps, and the platform team owns the platform. Granular RBAC You can set different permissions for each repository. For example, only the Platform team can approve PRs to the platform repo. Reduced Blast Radius A mistake in an application repository is unlikely to take down your entire platform. Changes are isolated to their respective domains. Scalability As your organization grows, you can easily add new application and infrastructure repositories without creating conflicts in a single repo."},{"location":"repository-management/01-multi-repo-strategy/#the-role-of-the-platform-repo","title":"The Role of the Platform Repo","text":"<p>This repository, <code>crossplane-gitops-tutorial</code>, serves as the Platform Repository. It is the heart of our system. The Crossplane Compositions we define here are published to the Kubernetes API server as new CRDs (e.g., <code>CompositePostgresInstance.example.org</code>).</p> <p>Other repositories can then create instances of these CRDs (Claims) without needing to know the complex implementation details. They are consuming the API provided by the platform.</p> <p>In the next section, we will look at how to standardize the creation of these repositories using templates.</p> <p>\u27a1\ufe0f Next: Repository Templates</p>"},{"location":"repository-management/02-repository-templates/","title":"02: Repository Templates","text":"<p>To make our multi-repo strategy scalable, we need to make it easy for teams to create new infrastructure and application repositories that adhere to our standards. GitHub Templates are an excellent way to achieve this.</p> <p>We have provided two templates in the <code>repository-templates/</code> directory:</p> <ol> <li><code>template-infra-composition</code>: A template for creating new Crossplane Compositions.</li> <li><code>template-microservice</code>: A template for a standard microservice, including its Kubernetes manifests.</li> </ol>"},{"location":"repository-management/02-repository-templates/#template-1-template-infra-composition","title":"Template 1: <code>template-infra-composition</code>","text":"<p>This template provides the basic scaffolding for defining a new type of infrastructure \"product\" that your platform will offer.</p> <p>File: <code>repository-templates/template-infra-composition/composition.yaml</code></p> <pre><code># --- This file is a template. To use it, copy this directory and update the content. ---\napiVersion: apiextensions.crossplane.io/v1\nkind: CompositeResourceDefinition\nmetadata:\n  name: # e.g., compositemysqlinstances.database.example.org\nspec:\n  group: # e.g., database.example.org\n  names:\n    kind: # e.g., CompositeMySQLInstance\n    plural: # e.g., compositemysqlinstances\n  claimNames:\n    kind: # e.g., MySQLInstance\n    plural: # e.g., mysqlinstances\n  versions:\n    - name: v1alpha1\n      served: true\n      referenceable: true\n      schema:\n        openAPIV3Schema:\n          type: object\n          properties:\n            spec:\n              type: object\n              properties:\n                # Add your claim fields here\n                # e.g., storageGB, region, version\n              required: []\n---\napiVersion: apiextensions.crossplane.io/v1\nkind: Composition\nmetadata:\n  name: # e.g., azure-mysql-server.v1alpha1.database.example.org\n  labels:\n    provider: azure\n    # Add other identifying labels\nspec:\n  compositeTypeRef:\n    apiVersion: # e.g., database.example.org/v1alpha1\n    kind: # e.g., CompositeMySQLInstance\n  resources:\n    # Define the cloud resources that make up this Composition\n    # e.g., azure.dbformysql.flexible.FlexibleServer, azure.dbformysql.flexible.FirewallRule\n    - name: my-resource\n      base:\n        apiVersion: #\n        kind: #\n        spec: #\n</code></pre>"},{"location":"repository-management/02-repository-templates/#how-to-use-it","title":"How to Use It","text":"<ol> <li>Create a New Repository: A platform engineer who wants to define a new infrastructure type (e.g., a Redis cluster) would create a new repository from this template.</li> <li>Define the XRD: They would fill out the <code>CompositeResourceDefinition</code> (XRD). The XRD defines the API for the new resource type. It specifies the fields that a developer can set in their \"claim\" (e.g., <code>version</code>, <code>size</code>).</li> <li>Define the Composition: They would then fill out the <code>Composition</code>. The Composition defines which actual cloud resources (e.g., <code>azurerm_redis_cache</code>, <code>google_redis_instance</code>) will be created to satisfy the claim.</li> <li>Commit and Push: They commit this file to their new repository.</li> </ol>"},{"location":"repository-management/02-repository-templates/#template-2-template-microservice","title":"Template 2: <code>template-microservice</code>","text":"<p>This template provides a starting point for a new microservice.</p> <p>File: <code>repository-templates/template-microservice/deployment.yaml</code></p> <pre><code># --- This file is a template. To use it, copy this directory and update the content. ---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: # my-app\n  namespace: # my-namespace\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: # my-app\n  template:\n    metadata:\n      labels:\n        app: # my-app\n    spec:\n      containers:\n        - name: # my-app\n          image: # my-registry/my-app:latest\n          ports:\n            - containerPort: 8080\n</code></pre>"},{"location":"repository-management/02-repository-templates/#how-to-use-it_1","title":"How to Use It","text":"<ol> <li>Create a New Repository: A developer starting a new microservice would create a new repository from this template.</li> <li>Add Source Code: They would add their application source code (e.g., <code>main.go</code>, <code>app.py</code>).</li> <li>Update Deployment Manifest: They would update the <code>deployment.yaml</code> with the correct image name, container port, and other application-specific settings.</li> <li>Commit and Push: They commit their code and the manifest to their new repository.</li> </ol> <p>By providing these templates, we lower the barrier to entry and ensure that all new components in our ecosystem follow a consistent structure.</p> <p>\u27a1\ufe0f Next: Cross-Repo Coordination</p>"},{"location":"repository-management/03-cross-repo-coordination/","title":"03: Cross-Repo Coordination with ArgoCD","text":"<p>Our multi-repo strategy is powerful, but it introduces a new challenge: how do we make all these repositories work together? How does ArgoCD discover and deploy all the Compositions, Claims, and Applications defined across our entire organization?</p> <p>The answer lies back in the Platform Core ApplicationSet pattern.</p>"},{"location":"repository-management/03-cross-repo-coordination/#revisiting-the-platform-coreyaml","title":"Revisiting the <code>platform-core.yaml</code>","text":"<p>Our bootstrap <code>platform-core.yaml</code> manifest deploys other ArgoCD <code>Application</code> resources. Let's look at the <code>gitops-bootstrap/apps</code> directory that it points to.</p> <p>Imagine this structure:</p> <p><code>gitops-bootstrap/apps/</code> \u251c\u2500\u2500 <code>platform.yaml</code> \u251c\u2500\u2500 <code>infra-dev.yaml</code> \u2514\u2500\u2500 <code>infra-prod.yaml</code></p>"},{"location":"repository-management/03-cross-repo-coordination/#platformyaml","title":"<code>platform.yaml</code>","text":"<p>This file tells ArgoCD to monitor all repositories that contain our core platform definitions (like Compositions).</p> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: platform-compositions\n  namespace: argocd\nspec:\n  project: default\n  source:\n    # We use a repo glob to discover all repos matching a pattern\n    repoURL: https://github.com/your-org/composition-*\n    targetRevision: HEAD\n    path: './' # Look at the root of each discovered repo\n  destination:\n    server: https://kubernetes.default.svc\n    # Compositions are cluster-scoped, so no namespace is needed\n  syncPolicy:\n    automated:\n      prune: true\n      selfHeal: true\n</code></pre> <p>Key Idea: We can use wildcards (<code>*</code>) in the <code>repoURL</code>. This single <code>Application</code> manifest tells ArgoCD to find every repository in your GitHub organization that starts with <code>composition-</code>, and deploy any <code>.yaml</code> or <code>.json</code> files it finds in them. This is how our platform automatically discovers and installs new infrastructure blueprints.</p>"},{"location":"repository-management/03-cross-repo-coordination/#infra-devyaml","title":"<code>infra-dev.yaml</code>","text":"<p>This file tells ArgoCD to deploy the infrastructure claims for the <code>dev</code> environment.</p> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: infra-dev\n  namespace: argocd\nspec:\n  project: default\n  source:\n    repoURL: https://github.com/your-org/infra-dev.git\n    targetRevision: HEAD\n    path: './'\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: crossplane-claims # We deploy claims to a dedicated namespace\n  syncPolicy:\n    automated:\n      prune: true\n      selfHeal: true\n</code></pre> <p>This is a more traditional ArgoCD Application, pointing to a single repository that contains all the infrastructure claims for the development environment.</p>"},{"location":"repository-management/03-cross-repo-coordination/#the-complete-workflow","title":"The Complete Workflow","text":"<p>Now, let's put it all together.</p> <ol> <li> <p>A Platform Engineer wants to offer a new database type.</p> <ul> <li>They create a new repository <code>composition-postgres-ha</code> from the <code>template-infra-composition</code>.</li> <li>They define the XRD and Composition for a highly-available PostgreSQL cluster.</li> <li>They push the repository to the <code>your-org</code> GitHub organization.</li> <li>ArgoCD's <code>platform-compositions</code> app automatically discovers the new repo and installs the Composition into the cluster.</li> <li>The new CRD, <code>CompositePostgresHA</code>, is now available in the Kubernetes API.</li> </ul> </li> <li> <p>A Developer needs a new HA PostgreSQL database for their project.</p> <ul> <li>They open a pull request against the <code>infra-dev</code> repository.</li> <li>They add a new file, <code>my-project-db.yaml</code>, containing the claim:     <pre><code>apiVersion: database.example.org/v1alpha1\nkind: PostgresHA\nmetadata:\n  name: my-project-db\nspec:\n  storageGB: 50\n  region: us-east-1\n</code></pre></li> <li>The pull request is reviewed and merged by the DevOps team.</li> <li>ArgoCD's <code>infra-dev</code> app sees the new file and applies it to the cluster.</li> <li>Crossplane sees the new <code>PostgresHA</code> claim.</li> <li>It finds the <code>composition-postgres-ha</code> Composition and starts provisioning all the necessary cloud resources (e.g., a primary database, a read replica, firewall rules, etc.).</li> </ul> </li> </ol> <p>This elegant workflow allows for seamless coordination across multiple teams and repositories, all orchestrated through Git and ArgoCD.</p> <p>\u27a1\ufe0f Next Section: GitOps Fundamentals</p>"},{"location":"security/","title":"Security","text":""},{"location":"security/01-chainguard-images/","title":"01: Securing the Supply Chain with Chainguard Images","text":"<p>Our infrastructure is defined by code, but it runs on container images. The security of our control plane (Crossplane, ArgoCD, and all the Crossplane Providers) is paramount. A vulnerability in one of these components could compromise our entire system.</p> <p>This is why we use Chainguard Images.</p>"},{"location":"security/01-chainguard-images/#what-are-chainguard-images","title":"What are Chainguard Images?","text":"<p>Chainguard produces minimalist, hardened container images with a near-zero vulnerability count. They are built from source, signed, and continuously scanned.</p> <p>Key features:</p> <ul> <li>Minimalism: Images contain only the application and its direct dependencies. There is no shell, package manager, or other unnecessary tooling that could be exploited.</li> <li>SBOMs: Every image comes with a Software Bill of Materials (SBOM), giving you a complete inventory of every component in the image.</li> <li>Signed: Images are signed with Sigstore, allowing you to verify their integrity and provenance.</li> </ul> <p>By using Chainguard images for our control plane components, we drastically reduce our attack surface.</p>"},{"location":"security/01-chainguard-images/#how-we-use-chainguard-images","title":"How We Use Chainguard Images","text":"<p>We have configured our Helm charts for Crossplane and ArgoCD to use Chainguard images instead of the default upstream images.</p> <p>Example: Overriding the Crossplane image in its Helm Chart</p> <p>When installing the Crossplane Helm chart, you can override the image registry and repository:</p> <pre><code>helm install crossplane crossplane-stable/crossplane \\\n  --namespace crossplane-system \\\n  --set image.repository=cgr.dev/chainguard/crossplane \\\n  --set image.tag=v1.15.0\n</code></pre> <p>We have pre-configured these overrides in our bootstrap process. When you installed Crossplane and ArgoCD in the \"Getting Started\" module, you were already using the hardened Chainguard versions.</p>"},{"location":"security/01-chainguard-images/#verifying-image-signatures-with-kyverno","title":"Verifying Image Signatures with Kyverno","text":"<p>It's not enough to just use secure images; we need to enforce that only secure, signed images can run in our cluster. We can use a policy engine like Kyverno to do this.</p> <p>Here is an example Kyverno <code>ClusterPolicy</code> that enforces image signature verification:</p> <pre><code>apiVersion: kyverno.io/v1\nkind: ClusterPolicy\nmetadata:\n  name: check-image-signature\nspec:\n  validationFailureAction: Enforce\n  rules:\n    - name: check-chainguard-signature\n      match:\n        any:\n        - resources:\n            kinds:\n              - Pod\n      verifyImages:\n      - imageReferences:\n        - \"cgr.dev/chainguard/*\"\n      attestors:\n      - count: 1\n        entries:\n        - keyless:\n            subject: \"https://github.com/chainguard-images/images/.github/workflows/release.yaml@refs/heads/main\"\n            issuer: \"https://token.actions.githubusercontent.com\"\n</code></pre> <p>This policy instructs the Kubernetes API server to:</p> <ol> <li>Intercept all <code>Pod</code> creation requests.</li> <li>If the pod uses an image from <code>cgr.dev/chainguard/</code>, verify its signature.</li> <li>The signature must come from the official Chainguard release pipeline on GitHub.</li> <li>If the signature is invalid or missing, reject the pod creation request.</li> </ol> <p>This provides a strong guarantee that only authorized, unmodified container images are running in our cluster.</p>"},{"location":"security/01-chainguard-images/#exercise-enforcing-policy","title":"Exercise: Enforcing Policy","text":"<p>Objective: Add a Kyverno policy to the <code>platform</code> repository to enforce that all Crossplane Provider pods must also come from the Chainguard registry.</p> <p>Tasks:</p> <ol> <li>Install Kyverno into your KinD cluster.</li> <li>Create a new <code>ClusterPolicy</code> manifest.</li> <li>The policy should match all pods in the <code>crossplane-system</code> namespace.</li> <li>It should verify that any image matching <code>cgr.dev/chainguard/provider-*</code> is properly signed.</li> <li>Add the policy to the <code>gitops-bootstrap/apps/platform</code> directory.</li> <li>Commit and push the change.</li> <li>Verify in the ArgoCD UI that the policy is synced and active.</li> </ol> <p>This exercise demonstrates how to use GitOps to manage not just your infrastructure, but your security policies as well.</p> <p>\u27a1\ufe0f Next: Secret Management</p>"},{"location":"security/02-secret-management/","title":"02: Secret Management in a GitOps World","text":"<p>One of the biggest challenges in a GitOps workflow is managing secrets. Git is a public, version-controlled system, which is the worst possible place to store sensitive information like API keys, database passwords, or TLS certificates.</p> <p>We need a robust solution for managing secrets that integrates with our GitOps workflow without compromising security.</p>"},{"location":"security/02-secret-management/#the-problem-with-secrets-in-git","title":"The Problem with Secrets in Git","text":"<ul> <li>Exposure: Committing a secret to a Git repository, even a private one, is a huge risk. Once it's in the Git history, it's very difficult to truly purge.</li> <li>Manual Workflows: If secrets aren't in Git, how do you get them to the cluster? Manual <code>kubectl create secret</code> commands are error-prone, not auditable, and don't scale.</li> </ul>"},{"location":"security/02-secret-management/#solution-external-secrets-operator","title":"Solution: External Secrets Operator","text":"<p>We will use the External Secrets Operator (ESO). ESO extends Kubernetes with a set of CRDs that allow you to fetch secrets from an external secret management system (like AWS Secrets Manager, Azure Key Vault, or HashiCorp Vault) and automatically sync them as native Kubernetes <code>Secret</code> objects.</p>"},{"location":"security/02-secret-management/#the-workflow","title":"The Workflow","text":"<ol> <li> <p>Store the Secret: A human or a CI/CD pipeline stores a secret in your chosen secret management system (e.g., Azure Key Vault).</p> </li> <li> <p>Create a <code>SecretStore</code>: In your Git repository, you create a <code>SecretStore</code> or <code>ClusterSecretStore</code> resource. This tells ESO how to connect to your external secret manager.</p> <pre><code># platform/secret-stores/azure-key-vault.yaml\napiVersion: external-secrets.io/v1beta1\nkind: ClusterSecretStore\nmetadata:\n  name: azure-key-vault\nspec:\n  provider:\n    azure:\n      vaultUrl: \"https://my-key-vault.vault.azure.net/\"\n      authType: \"WorkloadIdentity\"\n</code></pre> </li> <li> <p>Create an <code>ExternalSecret</code>: In your application or infrastructure repository, you create an <code>ExternalSecret</code> resource. This tells ESO which secret to fetch and what to name the resulting Kubernetes <code>Secret</code>.</p> <pre><code># infra-dev/my-app-db-secret.yaml\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: my-app-db-credentials\n  namespace: my-app\nspec:\n  refreshInterval: \"1h\"\n  secretStoreRef:\n    name: azure-key-vault\n    kind: ClusterSecretStore\n  target:\n    name: my-app-db-credentials # Name of the k8s Secret to create\n  data:\n  - secretKey: \"password\"\n    remoteRef:\n      key: \"my-app-db-password\" # Name of the secret in Azure Key Vault\n</code></pre> </li> <li> <p>ArgoCD Syncs: ArgoCD syncs the <code>ExternalSecret</code> manifest from Git to the cluster.</p> </li> <li> <p>ESO Syncs: The External Secrets Operator sees the new <code>ExternalSecret</code>. It connects to Azure Key Vault, fetches the value of <code>my-app-db-password</code>, and creates a new Kubernetes <code>Secret</code> named <code>my-app-db-credentials</code> in the <code>my-app</code> namespace with the fetched value.</p> </li> <li> <p>Pod Consumes the Secret: Your application pod can now mount the <code>my-app-db-credentials</code> secret just like any other Kubernetes secret.</p> </li> </ol>"},{"location":"security/02-secret-management/#benefits-of-this-approach","title":"Benefits of this Approach","text":"<ul> <li>No Secrets in Git: The actual secret value never touches the Git repository.</li> <li>GitOps Native: The request for a secret is managed via GitOps. We have a full audit trail of who requested which secret and for what purpose.</li> <li>Rotation: ESO can be configured to automatically re-fetch secrets on a schedule, enabling automated secret rotation.</li> <li>Separation of Concerns: The Platform Team manages the <code>SecretStores</code>, and the Application Teams manage the <code>ExternalSecrets</code> for their own applications.</li> </ul>"},{"location":"security/02-secret-management/#crossplane-and-secret-management","title":"Crossplane and Secret Management","text":"<p>Crossplane also needs to store secrets. When Crossplane provisions a database, it generates a password. This password needs to be stored somewhere so that applications can consume it.</p> <p>Crossplane is configured to automatically write these generated secrets to a Kubernetes <code>Secret</code> object. We can then use ESO to push these secrets from the Kubernetes <code>Secret</code> into a central secret manager like Azure Key Vault.</p> <p>This creates a closed-loop system:</p> <ol> <li>Crossplane creates a database and a Kubernetes <code>Secret</code> with the password.</li> <li>An <code>ExternalSecret</code> is configured to read from this Kubernetes <code>Secret</code>.</li> <li>ESO pushes the password into Azure Key Vault.</li> <li>Another application can then use a different <code>ExternalSecret</code> to read the password from Azure Key Vault.</li> </ol> <p>\u27a1\ufe0f Next: RBAC</p>"},{"location":"security/03-rbac/","title":"03: RBAC and Least Privilege","text":"<p>Role-Based Access Control (RBAC) is a critical component of a secure Kubernetes environment. In our GitOps model, we need to manage RBAC for two distinct domains:</p> <ol> <li>Who can do what in the Kubernetes cluster? (Kubernetes RBAC)</li> <li>Who can do what in our Git repositories? (Git Provider RBAC)</li> </ol>"},{"location":"security/03-rbac/#kubernetes-rbac","title":"Kubernetes RBAC","text":"<p>Our goal is the principle of least privilege. Every user and every component should only have the permissions they absolutely need to perform their function.</p>"},{"location":"security/03-rbac/#argocd-rbac","title":"ArgoCD RBAC","text":"<p>We have already configured the RBAC for the ArgoCD controllers. But what about human users?</p> <p>ArgoCD has its own RBAC system for controlling who can manage applications, projects, and repositories within the ArgoCD UI and API.</p> <p>We can manage this declaratively in the <code>argocd-rbac-cm</code> ConfigMap.</p> <p>Example: Granting a <code>dev-team</code> group read-only access to their project.</p> <pre><code># argocd-rbac-cm.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: argocd-rbac-cm\n  namespace: argocd\ndata:\n  policy.csv: |\n    g, dev-team, role:readonly\n    p, role:readonly, applications, get, dev-project/*, allow\n</code></pre> <p>This configuration, when applied by our bootstrap ArgoCD app, will:</p> <ul> <li>Define a group called <code>dev-team</code>.</li> <li>Assign it a <code>readonly</code> role.</li> <li>The <code>readonly</code> role is allowed to <code>get</code> applications within the <code>dev-project</code>.</li> </ul>"},{"location":"security/03-rbac/#crossplane-rbac","title":"Crossplane RBAC","text":"<p>Crossplane introduces a new layer of RBAC. Who is allowed to create a <code>Claim</code> for a new database? Who is allowed to create a <code>Composition</code>?</p> <p>We manage this with standard Kubernetes <code>Roles</code> and <code>RoleBindings</code>.</p> <p>Example: Allowing the <code>dev-team</code> to create <code>MySQLInstance</code> claims.</p> <pre><code># rbac/dev-team-role.yaml\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  name: dev-team-claim-creator\n  namespace: default # Or the namespace where claims are created\nrules:\n- apiGroups:\n  - \"database.example.org\"\n  resources:\n  - \"mysqlinstances\"\n  verbs:\n  - \"create\"\n  - \"get\"\n  - \"list\"\n  - \"watch\"\n  - \"delete\"\n---\n# rbac/dev-team-binding.yaml\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: dev-team-claim-binding\n  namespace: default\nsubjects:\n- kind: Group\n  name: dev-team\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: Role\n  name: dev-team-claim-creator\n  apiGroup: rbac.authorization.k8s.io\n</code></pre> <p>These manifests are stored in our <code>platform</code> repository and synced by ArgoCD, ensuring that our RBAC policies are also managed via GitOps.</p>"},{"location":"security/03-rbac/#git-provider-rbac","title":"Git Provider RBAC","text":"<p>Equally important is the RBAC in your Git provider (e.g., GitHub, GitLab).</p>"},{"location":"security/03-rbac/#branch-protection-rules","title":"Branch Protection Rules","text":"<ul> <li><code>platform</code> repository: The <code>main</code> branch should be heavily protected. Require multiple approvers from the Platform Team for all pull requests. Forbid force pushing.</li> <li><code>infra-*</code> repositories: The <code>main</code> branch should be protected. Require at least one approval from a senior member of the DevOps/SRE team.</li> <li>Application repositories: The <code>main</code> branch should be protected. Require at least one approval from a peer developer.</li> </ul>"},{"location":"security/03-rbac/#codeowners","title":"CODEOWNERS","text":"<p>Use the <code>CODEOWNERS</code> file in each repository to automatically request reviews from the responsible team.</p> <p>Example: <code>platform/.github/CODEOWNERS</code></p> <pre><code># All changes to Compositions must be reviewed by the platform team\n/compositions/  @my-org/platform-team\n\n# Changes to RBAC policies require security review\n/rbac/          @my-org/security-team\n</code></pre> <p>By codifying our RBAC policies in both Kubernetes and Git, we create a secure, auditable, and automated system for managing permissions.</p> <p>\u27a1\ufe0f Next Section: Observability</p>"}]}